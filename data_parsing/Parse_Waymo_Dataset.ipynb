{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-hp2_PC8Las",
        "outputId": "089f8d02-9e80-49c0-ae49-388e6d83842d"
      },
      "outputs": [],
      "source": [
        "!pip install waymo-open-dataset-tf-2-12-0==1.6.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EC53bb8a9Iux",
        "outputId": "2922c93b-a529-4a95-e4fe-d2c3de3c6f44"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uX5avSNw9N1E",
        "outputId": "5f431eb2-1069-42ff-8904-7f91479ff3f1"
      },
      "outputs": [],
      "source": [
        "#Cell 2\n",
        "import os\n",
        "# TODO: Enter the relative path in your Google Drive to the unzipped folder for hw1_code_submission.zip\n",
        "FOLDERNAME = 'CS7643Group/Dataset/training' # e.g. 'cs7643/hw1/Code'\n",
        "\n",
        "assert FOLDERNAME is not None, \"[!] Enter the foldername.\"\n",
        "working_directory = os.path.join(\"/content/drive/MyDrive/\", FOLDERNAME)\n",
        "assert os.path.exists(working_directory), \"Make sure your FOLDERNAME is correct\"\n",
        "%cd $working_directory\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vPdpgeyr-BZm",
        "outputId": "4b1a93f6-a284-446f-a046-471e9520dca2"
      },
      "outputs": [],
      "source": [
        "import glob\n",
        "\n",
        "# Define the path to your training folder\n",
        "tfrecord_folder = '/content/drive/MyDrive/CS7643Group/Dataset/training/'\n",
        "\n",
        "# Get a list of all .tfrecord files in the folder\n",
        "tfrecord_files = glob.glob(os.path.join(tfrecord_folder, '*.tfrecord*'))\n",
        "\n",
        "# Check how many tfrecord files were found\n",
        "print(f\"Found {len(tfrecord_files)} .tfrecord files.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m7WyUdPEEszB"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import uuid\n",
        "import time\n",
        "\n",
        "from matplotlib import cm\n",
        "import matplotlib.animation as animation\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "from IPython.display import HTML\n",
        "import itertools\n",
        "import tensorflow as tf\n",
        "\n",
        "from google.protobuf import text_format\n",
        "from waymo_open_dataset.metrics.ops import py_metrics_ops\n",
        "from waymo_open_dataset.metrics.python import config_util_py as config_util\n",
        "from waymo_open_dataset.protos import motion_metrics_pb2\n",
        "\n",
        "# If you use a custom conversion from Scenario to tf.Example, set the correct\n",
        "# number of map samples here.\n",
        "num_map_samples = 30000\n",
        "\n",
        "# # Example field definition\n",
        "roadgraph_features = {\n",
        "    'roadgraph_samples/dir': tf.io.FixedLenFeature(\n",
        "        [num_map_samples, 3], tf.float32, default_value=None\n",
        "    ),\n",
        "    'roadgraph_samples/id': tf.io.FixedLenFeature(\n",
        "        [num_map_samples, 1], tf.int64, default_value=None\n",
        "    ),\n",
        "    'roadgraph_samples/type': tf.io.FixedLenFeature(\n",
        "        [num_map_samples, 1], tf.int64, default_value=None\n",
        "    ),\n",
        "    'roadgraph_samples/valid': tf.io.FixedLenFeature(\n",
        "        [num_map_samples, 1], tf.int64, default_value=None\n",
        "    ),\n",
        "    'roadgraph_samples/xyz': tf.io.FixedLenFeature(\n",
        "        [num_map_samples, 3], tf.float32, default_value=None\n",
        "    ),\n",
        "}\n",
        "# Features of other agents.\n",
        "state_features = {\n",
        "    'state/id':\n",
        "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
        "    'state/type':\n",
        "        tf.io.FixedLenFeature([128], tf.float32, default_value=None),\n",
        "    'state/is_sdc':\n",
        "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
        "    'state/tracks_to_predict':\n",
        "        tf.io.FixedLenFeature([128], tf.int64, default_value=None),\n",
        "    'state/current/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/height':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/length':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
        "    'state/current/valid':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.int64, default_value=None),\n",
        "    'state/current/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/width':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/x':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/y':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/current/z':\n",
        "        tf.io.FixedLenFeature([128, 1], tf.float32, default_value=None),\n",
        "    'state/future/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/height':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/length':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
        "    'state/future/valid':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.int64, default_value=None),\n",
        "    'state/future/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/width':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/x':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/y':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/future/z':\n",
        "        tf.io.FixedLenFeature([128, 80], tf.float32, default_value=None),\n",
        "    'state/past/bbox_yaw':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/height':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/length':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/timestamp_micros':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
        "    'state/past/valid':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.int64, default_value=None),\n",
        "    'state/past/vel_yaw':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/velocity_x':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/velocity_y':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/width':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/x':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/y':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "    'state/past/z':\n",
        "        tf.io.FixedLenFeature([128, 10], tf.float32, default_value=None),\n",
        "}\n",
        "# traffic_light_features = {\n",
        "#     'traffic_light_state/current/state':\n",
        "#         tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
        "#     'traffic_light_state/current/valid':\n",
        "#         tf.io.FixedLenFeature([1, 16], tf.int64, default_value=None),\n",
        "#     'traffic_light_state/current/x':\n",
        "#         tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "#     'traffic_light_state/current/y':\n",
        "#         tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "#     'traffic_light_state/current/z':\n",
        "#         tf.io.FixedLenFeature([1, 16], tf.float32, default_value=None),\n",
        "#     'traffic_light_state/past/state':\n",
        "#         tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
        "#     'traffic_light_state/past/valid':\n",
        "#         tf.io.FixedLenFeature([10, 16], tf.int64, default_value=None),\n",
        "#     'traffic_light_state/past/x':\n",
        "#         tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "#     'traffic_light_state/past/y':\n",
        "#         tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "#     'traffic_light_state/past/z':\n",
        "#         tf.io.FixedLenFeature([10, 16], tf.float32, default_value=None),\n",
        "# }\n",
        "\n",
        "features_description = {}\n",
        "features_description.update(roadgraph_features)\n",
        "features_description.update(state_features)\n",
        "# features_description.update(traffic_light_features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fjJLGziLG36P",
        "outputId": "cb255a1d-3667-4496-9ba9-5cbbe56a3203"
      },
      "outputs": [],
      "source": [
        "# Determine Number of Roadgraph samples\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "# Path to your TFRecord file\n",
        "tfrecord_file = \"/content/drive/MyDrive/training/training_tfexample.tfrecord-00000-of-01000\"\n",
        "\n",
        "# Define a minimal parsing schema to extract the size\n",
        "feature_description = {\n",
        "    'roadgraph_samples/xyz': tf.io.VarLenFeature(tf.float32)\n",
        "}\n",
        "\n",
        "# Function to parse one record\n",
        "def parse_tfrecord_fn(example_proto):\n",
        "    return tf.io.parse_single_example(example_proto, feature_description)\n",
        "\n",
        "# Load the TFRecord file\n",
        "dataset = tf.data.TFRecordDataset(tfrecord_file)\n",
        "\n",
        "# Parse one example to get the number of samples\n",
        "for raw_record in dataset.take(1):\n",
        "    parsed_record = parse_tfrecord_fn(raw_record)\n",
        "    num_samples_map = parsed_record['roadgraph_samples/xyz'].values.numpy().shape[0] // 3\n",
        "    break\n",
        "\n",
        "print(f\"Number of map samples: {num_samples_map}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jr28efUxLK3h",
        "outputId": "7257bd53-84b8-43fe-ecd9-c14694ab72ae"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# Path to your TFRecord file\n",
        "FILENAME = '/content/drive/MyDrive/CS7643Group/Dataset/training/training_tfexample.tfrecord-00000-of-01000'\n",
        "\n",
        "# List of state features (vehicle-related data)\n",
        "state_features_list = [\n",
        "    'state/id',\n",
        "    'state/type',\n",
        "    'state/is_sdc',\n",
        "    'state/tracks_to_predict',\n",
        "    'state/current/bbox_yaw',\n",
        "    'state/current/height',\n",
        "    'state/current/length',\n",
        "    'state/current/timestamp_micros',\n",
        "    'state/current/valid',\n",
        "    'state/current/vel_yaw',\n",
        "    'state/current/velocity_x',\n",
        "    'state/current/velocity_y',\n",
        "    'state/current/width',\n",
        "    'state/current/x',\n",
        "    'state/current/y',\n",
        "    'state/current/z',\n",
        "    'state/future/bbox_yaw',\n",
        "    'state/future/height',\n",
        "    'state/future/length',\n",
        "    'state/future/timestamp_micros',\n",
        "    'state/future/valid',\n",
        "    'state/future/vel_yaw',\n",
        "    'state/future/velocity_x',\n",
        "    'state/future/velocity_y',\n",
        "    'state/future/width',\n",
        "    'state/future/x',\n",
        "    'state/future/y',\n",
        "    'state/future/z',\n",
        "    'state/past/bbox_yaw',\n",
        "    'state/past/height',\n",
        "    'state/past/length',\n",
        "    'state/past/timestamp_micros',\n",
        "    'state/past/valid',\n",
        "    'state/past/vel_yaw',\n",
        "    'state/past/velocity_x',\n",
        "    'state/past/velocity_y',\n",
        "    'state/past/width',\n",
        "    'state/past/x',\n",
        "    'state/past/y',\n",
        "    'state/past/z'\n",
        "]\n",
        "\n",
        "# List of roadgraph features\n",
        "roadgraph_features_list = [\n",
        "    'roadgraph_samples/dir',\n",
        "    'roadgraph_samples/id',\n",
        "    'roadgraph_samples/type',\n",
        "    'roadgraph_samples/valid',\n",
        "    'roadgraph_samples/xyz'\n",
        "]\n",
        "\n",
        "# Helper function to find the nearest roadgraph sample for a given vehicle position\n",
        "def find_closest_roadgraph_sample(vehicle_position, roadgraph_samples, roadgraph_types):\n",
        "    \"\"\"\n",
        "    Finds the closest roadgraph sample and its type for a given vehicle position.\n",
        "    Args:\n",
        "        vehicle_position: (x, y) tuple of vehicle coordinates.\n",
        "        roadgraph_samples: Array of roadgraph sample positions (N x 3 for xyz).\n",
        "        roadgraph_types: Array of roadgraph sample types (N x 1).\n",
        "    Returns:\n",
        "        The closest roadgraph sample (x, y, z) and its type.\n",
        "    \"\"\"\n",
        "    vehicle_x, vehicle_y = vehicle_position\n",
        "    distances = np.linalg.norm(roadgraph_samples[:, :2] - np.array([vehicle_x, vehicle_y]).T, axis=1)\n",
        "    closest_idx = np.argmin(distances)\n",
        "    return roadgraph_samples[closest_idx], roadgraph_types[closest_idx][0]\n",
        "\n",
        "# Load the dataset\n",
        "dataset = tf.data.TFRecordDataset(FILENAME, compression_type='')\n",
        "\n",
        "j = 0  # Counter for processed examples\n",
        "vehicles_list = []  # Stores combined data for all vehicles and roadgraph info\n",
        "vehicles = 0  # Counter for total vehicles processed\n",
        "\n",
        "for raw_record in dataset:\n",
        "    j += 1\n",
        "    if j == 200:  # Process only the first 200 examples for this demonstration\n",
        "        break\n",
        "\n",
        "    # Parse each raw record using the feature description\n",
        "    parsed_example = tf.io.parse_single_example(raw_record, features_description)\n",
        "\n",
        "\n",
        "    # Vehicle parsing: Extract vehicle data and filter by type\n",
        "    numpy_array = parsed_example['state/type'].numpy()\n",
        "    parsed_type = torch.from_numpy(numpy_array)\n",
        "    vehicle_indices = torch.where(parsed_type == 1.0)[0].tolist()  # Indices of vehicles\n",
        "    vehicles += len(vehicle_indices)\n",
        "\n",
        "    # Roadgraph parsing: Extract roadgraph data and filter valid samples\n",
        "    roadgraph_samples = np.array(parsed_example['roadgraph_samples/xyz'].numpy())  # Roadgraph positions\n",
        "    roadgraph_types = np.array(parsed_example['roadgraph_samples/type'].numpy())  # Roadgraph types\n",
        "    roadgraph_valid = np.array(parsed_example['roadgraph_samples/valid'].numpy())  # Validity flags\n",
        "    valid_indices = roadgraph_valid.flatten() == 1  # Boolean mask for valid samples\n",
        "    valid_roadgraph_samples = roadgraph_samples[valid_indices]  # Filtered roadgraph positions\n",
        "    valid_roadgraph_types = roadgraph_types[valid_indices]  # Filtered roadgraph types\n",
        "\n",
        "\n",
        "    # Combine vehicle and roadgraph data\n",
        "    for i in vehicle_indices:\n",
        "      data_point = {\n",
        "          'vehicle': {key: parsed_example[key][i].numpy() for key in state_features_list if key in parsed_example},\n",
        "          'roadgraph': [],  # To store 91 roadgraph samples (position + type) for 91 timesteps\n",
        "          'cyclists': [],\n",
        "          'pedestrians' : []\n",
        "      }\n",
        "\n",
        "      # go through the type array and see where the pedestrians are, and do same thing for cyclists (torch.where)\n",
        "      ped_indices = torch.where(parsed_type == 2.0)[0].tolist()\n",
        "      cyclist_indcies = torch.where(parsed_type == 3.0)[0].tolist()\n",
        "      # where the indices are, extract position information for the p number of pedestrians across all 91 timesteps\n",
        "      pedestrian_data = {}\n",
        "      pedestrian_data['state/past/x'] = parsed_example['state/past/x'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/past/y'] = parsed_example['state/past/y'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/current/x'] = parsed_example['state/current/x'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/current/y'] = parsed_example['state/current/y'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/future/x'] = parsed_example['state/future/x'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/future/y'] = parsed_example['state/future/y'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/past/valid'] = parsed_example['state/past/valid'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/current/valid'] = parsed_example['state/current/valid'].numpy()[ped_indices,:]\n",
        "      pedestrian_data['state/future/valid'] = parsed_example['state/future/valid'].numpy()[ped_indices,:]\n",
        "      data_point['pedestrians'].append(pedestrian_data)\n",
        "      # where the indices are, extract position information for the c number of cyclists across all 91 timesteps\n",
        "      cyclist_data = {}\n",
        "      cyclist_data['state/past/x'] = parsed_example['state/past/x'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/past/y'] = parsed_example['state/past/y'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/current/x'] = parsed_example['state/current/x'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/current/y'] = parsed_example['state/current/y'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/future/x'] = parsed_example['state/future/x'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/future/y'] = parsed_example['state/future/y'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/past/valid'] = parsed_example['state/past/valid'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/current/valid'] = parsed_example['state/current/valid'].numpy()[cyclist_indcies,:]\n",
        "      cyclist_data['state/future/valid'] = parsed_example['state/future/valid'].numpy()[cyclist_indcies,:]\n",
        "      data_point['cyclists'].append(cyclist_data)\n",
        "\n",
        "      # Iterate over the 91 timesteps (10 past, 1 current, 80 future)\n",
        "      for t in range(10):  # Past timesteps\n",
        "          # print(parsed_example['state/past/x'].shape)\n",
        "          vehicle_position = (\n",
        "              parsed_example['state/past/x'][i, t].numpy(),\n",
        "              parsed_example['state/past/y'][i, t].numpy()\n",
        "          )\n",
        "          closest_sample, sample_type = find_closest_roadgraph_sample(vehicle_position, valid_roadgraph_samples, valid_roadgraph_types)\n",
        "          data_point['roadgraph'].append({'xyz': closest_sample, 'type': sample_type})\n",
        "\n",
        "\n",
        "      # Current timestep\n",
        "      current_position = (\n",
        "          parsed_example['state/current/x'][t].numpy(),\n",
        "          parsed_example['state/current/y'][t].numpy()\n",
        "      )\n",
        "      closest_sample, sample_type = find_closest_roadgraph_sample(current_position, valid_roadgraph_samples, valid_roadgraph_types)\n",
        "      data_point['roadgraph'].append({'xyz': closest_sample, 'type': sample_type})\n",
        "\n",
        "      # Future timesteps\n",
        "      for t in range(80):\n",
        "          future_position = (\n",
        "              parsed_example['state/future/x'][i, t].numpy(),\n",
        "              parsed_example['state/future/y'][i, t].numpy()\n",
        "          )\n",
        "          closest_sample, sample_type = find_closest_roadgraph_sample(future_position, valid_roadgraph_samples, valid_roadgraph_types)\n",
        "          data_point['roadgraph'].append({'xyz': closest_sample, 'type': sample_type})\n",
        "\n",
        "      vehicles_list.append(data_point)\n",
        "\n",
        "# Output results\n",
        "print(f\"Processed {len(vehicles_list)} vehicles across {j-1} examples.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GxIF3WU1ZvPC"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "\n",
        "pickled_file_path = '/content/drive/MyDrive/CS7643Group/Dataset/training/pickled_waymo_external_actors_srishti.pkl'\n",
        "with open(pickled_file_path, 'wb') as file:\n",
        "  pickle.dump(vehicles_list, file)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
